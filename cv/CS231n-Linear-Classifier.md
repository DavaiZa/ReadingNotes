# Intro. 线性分类

线性分类比kNN更强, 而且也能更自然地推广到神经网络和卷积神经网络.

线性分类包括两个部分:

* **打分函数(Score function):** 把图片像素映射到类别分数.
* **损失函数(Loss function):** 量化衡量预测分类和答案的吻合度(agreement).

按照上述两部分看待线性分类模型, 就能把线性分类转化成数学上的最优化问题. 这里, 我们把打分函数的参数看成自变量, 找到使损失函数最小的参数取值.

# 1. 打分函数

## 1.1. 从像素到打分的参数化映射

规定:

* $$x_i$$: 第$$i$$个训练样本的(列)向量. 可能会问, 图片是二维的, 怎么变成一维? -- 把它展平(flatten)就变成一维的了.
  * $$x_i\in \mathbb{R}^D$$. 其中$$D$$是图片的像素数.
  * $$i=1..N$$. 其中$$N$$是训练样本数.
* $$y_i$$: 第$$i$$个训练样本的标签.
  * $$y_i=1..K$$. 其中$$K$$是类别数.
* $$f: \mathbb{R}^D\mapsto \mathbb{R}^K$$: 打分函数.


-----

**定义: 线性分类器**
$$
\forall x_i \in T, f\left(x_i\right)=Wx_i+b
$$
其中:

* $$x_i$$: 训练集$$T$$中的第$$i$$个样本. 已经被展平成$$1\times D$$的列向量.


* $$W$$: 权重矩阵, 形状为$$K\times D$$.
* $$b$$: 截距(bias), 也叫偏移量. 形状为$$1\times K$$.

-----

注意:

* 矩阵$$W$$的每一行都是一个分类器.
* 训练完以后, 知识记录在$$W$$和$$b$$中, 因此训练完后就不再需要训练集. 这点比kNN先进很多.

## 1.2. 权重矩阵W的诠释

因为输入的是颜色值, 所以这个映射函数实际上学到的是**喜欢/不喜欢某颜色出现在某位置**.

例如: 由于轮船通常出现在海上, 可以认为轮船的背景是大片蓝色的. 因此我们可以猜想, 权重矩阵W在"轮船"那一行上, 一定在蓝色通道上有很多正值, 而在其他通道上有很多负值.

----

**图1: 把图像映射到分数**

![img](https://cs231n.github.io/assets/imagemap.jpg)

为了视觉上的简便和直观, 我们假设

- 输入图像只有2x2=4个像素
- 输入图像是灰度图

注意图中的权重W并不好, 它把一只猫分成了狗.

-----

### 1.2.1. 用线性规划来解释

----

**图2: 每张训练图像被当成高维空间的点, 而权重矩阵的每一行都成为分类超平面**

实际上, W的每一行都是超平面的**法向量**(normal). 如果点出现在法向量所指的一侧(和法向量点乘为正) 则判定它是这一类的.

![img](https://cs231n.github.io/assets/pixelspace.jpeg)

----

### 1.2.2. 用模板匹配来解释

$$W$$的每一行实际上还可以理解成**模板**(template). 通过计算模板和图片的点乘, 得到图片在每一类上的得分.

笔者注: 这个想法和Dynamic Routing Between Capsules中的内积是相同的, 都是用内积来衡量相似度.

----

**图3: 线性分类器在CIFAR-10上学到的模板**

以ship为例, 和我们预想的一样, ship的模板有大量的蓝色.

![img](https://cs231n.github.io/assets/templates.jpg)

----

#### 特征合并现象

需要特别注意的是, 线性分类器有**特征合并**的现象.

以horse为例, 可以发现, 这是个双头马. 这是因为分类器学到了两种不同朝向的马, 并把这两种朝向的马叠加到一个模板里.

再以car为例, car的模板看起来叠加了各种朝向\各种颜色的车. 而最终的car模板看起来偏红, 这也说明CIFAR-10上红色的车偏多.

car的例子也提示我们, 线性分类器在学习不同颜色的车上表现很差.

## 1.3. 去掉讨厌的截距项 

给输入$$x_i$$追加一维, 这一维的值恒为1. 给权重矩阵追加一列, 这一列就是$$b$$. 这一块比较简单, 不记载了. 详见[CS231n - Linear Classifier](https://cs231n.github.io/linear-classify/#interpret)的Bias Trick部分.